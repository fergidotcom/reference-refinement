project_name: "Reference Refinement"
perspective_source: "mac_claude_code"
for_web_session: "Claude Code Web Session (NOT Claude.ai)"
timestamp: "2025-11-10T23:15:00Z"

urgent_goal: |
  COMPLETE ALL UNFINALIZED REFERENCES TONIGHT!

  Implement deep URL validation with ACTUAL CONTENT VERIFICATION, test with samples,
  then reprocess ALL 139 unfinalized references to finish the "Caught In The Act"
  reference list (288 total).

  CRITICAL: Before assigning PRIMARY or SECONDARY URL, you MUST actually access the
  site, fetch the content, and VERIFY you can see the target document (full text,
  images, etc.). Use as many queries and AI analysis as needed to confirm accessibility.

critical_lesson_learned: |
  ❌ WRONG APPROACH (v16.9 - REVERTED on Mac):
  - Penalized all jstor.org URLs based on domain alone
  - Assumed "JSTOR domain = always paywalled"
  - Reality: JSTOR hosts BOTH free AND paywalled content

  ✅ CORRECT APPROACH (v17.0 - FOR WEB):
  - Fetch URL and download first 50-100KB of content
  - Detect access barriers in actual page content:
    * Login walls: "Sign in to continue"
    * Paywalls: "Subscribe to read", "$XX to access"
    * Preview-only: "Limited preview", "5 pages shown"
    * Soft 404s: "Page not found", "Document unavailable"
  - Score based on ACCESSIBILITY not domain name
  - Verify content matches expected reference

user_directive: |
  "If Web gets a good sense of reliability after working this out and validating
  the new criteria at length, then have Web reprocess all of the outstanding
  Unfinalized references. Maybe we can get the whole Caught In The Act reference
  completed tonight!"

web_session_roadmap:
  total_time_estimate: "6-8 hours"
  goal: "Complete ALL 288 references (currently 149 finalized, 139 unfinalized)"

  phase_1_implementation:
    duration: "2-3 hours"
    tasks:
      - "Implement validate_url_deep() with content fetching"
      - "Add pattern detection (paywall/login/preview/soft-404)"
      - "Test with RID 5 (known accessible vs login-required)"
      - "Verify UCI PDF scores 90-100, Science.org scores 60-70"
      - "Confirm no false positives (accessible marked as paywalled)"

  phase_2_sample_testing:
    duration: "1-2 hours"
    sample_size: "25-50 references"
    tasks:
      - "Reprocess Sample 25 (RID 611-635)"
      - "Validate 25 additional diverse references"
      - "Measure accuracy: paywall detection, login detection"
      - "Calculate false positive rate"
      - "Generate reliability report"

  phase_3_go_no_go_decision:
    criteria_for_full_reprocess:
      - "Paywall detection: >90% accurate"
      - "Login detection: >90% accurate"
      - "False positive rate: <5%"
      - "Free sources score higher: 100% of cases"
      - "Processing time: <2 seconds per URL"
    if_criteria_met: "Proceed to Phase 4"
    if_not_met: "Refine and retest"

  phase_4_full_reprocess:
    duration: "3-4 hours"
    scope: "ALL 139 unfinalized references"
    approach: "Batches of 25-30 refs with progress logging"
    exclusion: "DO NOT touch 149 finalized references"
    logging: "Document every change: before/after URLs, validation results, scores"
    goal: "Complete 288/288 references tonight!"

current_state:
  decisions_txt:
    total_references: 288
    finalized: 149
    unfinalized: 139
    sample_25: "RID 611-635 (unfinalized)"

  unfinalized_breakdown:
    sample_25: "RID 611-635 (25 refs)"
    early_refs: "RID 122, 203, 204 (3 refs)"
    middle_batch: "RID 614-639 (26 refs)"
    remaining: "~85 refs scattered throughout"

  quality_target:
    accessibility_rate: ">85%"
    free_source_coverage: ">90%"
    paywall_elimination: "Detect and avoid"
    override_rate_target: "<5%"

implementation_details:
  validate_url_deep_function:
    critical_requirement: |
      YOU MUST ACTUALLY SEE THE TARGET DOCUMENT before assigning a URL.
      Don't just check HTTP status - fetch enough content to verify you can
      access the full text, images, or whatever the document type is.
      Use AI to analyze the retrieved content and confirm it's the actual
      reference, not a paywall page, preview, or different document.

    steps:
      1: "Fetch URL with redirects (GET request, follow up to 5 hops)"
      2: "Download first 50-100KB of content (MORE if needed to verify document)"
      3: "Detect access barriers using pattern matching"
      4: "Use AI to analyze content - can you ACTUALLY SEE the target document?"
      5: "Verify content matches reference (title/author/year/content snippets)"
      6: "If unclear, fetch MORE content or try additional queries"
      7: "Return accessibility score (0-100) and detailed verification reason"

    patterns_to_detect:
      paywall:
        - "subscribe to continue"
        - "subscription required"
        - "purchase this article"
        - "$XX.XX to access"
        - "you do not have access"
        - "institutional subscription required"

      login:
        - "sign in to continue"
        - "log in to view"
        - "login required"
        - "authentication required"
        - "access denied"

      preview:
        - "preview only"
        - "limited preview"
        - "read a preview"
        - "X pages shown"
        - "continue reading with subscription"

      soft_404:
        - "404 not found"
        - "page not found"
        - "document not available"
        - "doi not found"

    scoring_logic:
      free_full_text: "90-100 (accessible, no barriers)"
      free_borrow: "80-90 (archive.org 14-day borrow)"
      institutional: "60-75 (requires university login)"
      paywall: "45-60 (subscribe to access)"
      login_required: "40-55 (must sign in)"
      preview_only: "30-45 (limited pages)"
      not_found: "0 (404, soft 404, wrong content)"

test_case_rid_5:
  reference:
    id: 5
    title: "Judgment under uncertainty: Heuristics and biases"
    authors: "Tversky, A."
    year: 1974

  test_urls:
    uci_pdf:
      url: "https://sites.socsci.uci.edu/~bskyrms/bio/readings/tversky_k_heuristics_biases.pdf"
      expected_validation: "ACCESSIBLE (free PDF)"
      expected_score: "90-100"
      critical_note: "Domain LOOKS like JSTOR but is FREE - proves domain penalties wrong!"

    science_org:
      url: "https://www.science.org/doi/10.1126/science.185.4157.1124"
      expected_validation: "LOGIN REQUIRED"
      expected_score: "60-70"

  validation_requirement: "UCI PDF MUST score higher than Science.org"

processing_strategy:
  batching:
    batch_size: "25-30 references"
    reason: "Progress logging, error recovery, incremental validation"

  logging_per_reference:
    - "RID and title"
    - "Old PRIMARY/SECONDARY URLs (if any)"
    - "New PRIMARY/SECONDARY URLs"
    - "Validation results (accessible/paywall/login)"
    - "Scores before/after"
    - "Reason for change"

  error_handling:
    if_validation_fails: "Log error, skip reference, continue"
    if_no_candidates: "Flag as MANUAL_REVIEW"
    if_timeout: "Retry once, then skip"

  progress_tracking:
    every_25_refs: "Generate interim report"
    every_50_refs: "Checkpoint to disk"
    final: "Complete summary with statistics"

deliverables:
  implementation:
    - "Production_Quality_Framework_Enhanced.py (with validate_url_deep)"
    - "Validation helper functions"
    - "Integration with ranking workflow"

  reports:
    - "SAMPLE_25_REPROCESS_REPORT_V17_0.md"
    - "VALIDATION_SAMPLE_REPORT_V17_0.md (25-50 refs)"
    - "RELIABILITY_ASSESSMENT_V17_0.md (go/no-go decision)"
    - "FULL_REPROCESS_REPORT_V17_0.md (ALL 139 refs)"
    - "DEEP_VALIDATION_IMPLEMENTATION_V17_0.md"
    - "FOR_MAC_DEEP_VALIDATION_PROPAGATION.md"

  final_decisions_txt:
    - "Updated with ALL 288 references finalized"
    - "Backup of previous version"
    - "Change log documenting all modifications"

success_criteria:
  content_verification:
    - "MUST actually fetch and view target document content"
    - "AI analysis confirms document is accessible"
    - "Can see full text, images, or document body (not just abstract/preview)"
    - "Verify title/author/year match in actual retrieved content"
    - "Use multiple queries/fetches if needed to confirm"

  phase_2_testing:
    - "Paywall detection: >90% accurate"
    - "Login detection: >90% accurate"
    - "False positives: <5%"
    - "Free sources always score higher"
    - "RID 5 test passes (UCI PDF > Science.org)"
    - "CRITICAL: Verify you can actually SEE the documents in test cases"

  phase_4_completion:
    - "ALL 139 unfinalized references reprocessed"
    - "288/288 references completed"
    - "Accessibility rate: >85%"
    - "Free source coverage: >90%"
    - "Every URL verified by actually accessing the document"
    - "Comprehensive documentation generated"

  tonight_goal:
    - "Caught In The Act references COMPLETE (288/288)"
    - "Every URL verified accessible with actual content viewing"
    - "Ready for final user review"
    - "Mac propagation guide created"

files_for_web_session:
  primary_instructions:
    - "FOR_WEB_DEEP_VALIDATION_SESSION.md (Complete implementation guide)"
    - "DEEP_URL_VALIDATION_ARCHITECTURE.md (Technical architecture)"

  data_files:
    - "decisions.txt (149 finalized, 139 unfinalized)"
    - "Production_Quality_Framework_Enhanced.py (needs deep validation)"

  reference_docs:
    - "V16_9_JSTOR_PAYWALL_FIX.md (What NOT to do)"
    - "SESSION_SUMMARY_2025-11-10_JSTOR_FIX.md (Mac session summary)"

critical_reminders:
  - "This is Claude Code WEB session (NOT Claude.ai)"
  - "MUST actually access and VIEW the target document before assigning URL"
  - "Use as many queries and AI analysis as needed to verify accessibility"
  - "Don't just check HTTP status - FETCH and ANALYZE actual content"
  - "Can you see the full text? Images? Document body? Then it's accessible"
  - "If you see 'Subscribe', 'Sign in', or only preview - NOT accessible"
  - "Don't penalize by domain - validate by actual content viewing"
  - "JSTOR can host free content (RID 5 UCI PDF proves it)"
  - "Keep 149 finalized references intact - only reprocess 139 unfinalized"
  - "Goal: Complete ALL 288 references tonight with VERIFIED accessible URLs!"

timeline_estimate:
  phase_1_implementation: "2-3 hours (critical foundation)"
  phase_2_testing: "1-2 hours (validate reliability)"
  phase_3_decision: "15 minutes (review metrics, decide)"
  phase_4_full_reprocess: "3-4 hours (139 refs in batches)"
  documentation: "30 minutes (reports and summaries)"
  total: "6-8 hours (aggressive but achievable)"

motivation: |
  This is the final push to complete the Caught In The Act manuscript references!
  With deep URL validation, we can ensure every reference is accessible and high-quality.
  Let's finish all 288 references tonight!
